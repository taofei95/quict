{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install quict_sim first, you can use 'pip install quict_sim' to install. \n",
      "Please install pytorch, torch-geometric, torch-sparse, tensorboard, cupy and quict_ml first, you can use 'pip install quict-ml' to install quict_ml. \n",
      "Please install pytorch, cupy and quict_ml first, you can use 'pip install quict-ml' to install quict_ml. \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "import mindspore as ms\n",
    "from mindquantum.core.circuit import Circuit as HiqCircuit\n",
    "from mindquantum.core.gates import ZZ, XX\n",
    "from mindquantum.core.gates import H as HiqH\n",
    "from mindquantum.core.operators import Hamiltonian as HiqHamiltonian\n",
    "from mindquantum.core.operators import QubitOperator\n",
    "# from mindquantum.framework import MQAnsatzOnlyLayer\n",
    "from mindquantum.simulator import Simulator\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/zoker/quict\")\n",
    "from QuICT.algorithm.quantum_machine_learning.data import *\n",
    "from frqi import HIQFRQI\n",
    "from ansatz import HIQAnsatz\n",
    "from QuICT.algorithm.quantum_machine_learning.encoding import *\n",
    "from QuICT.simulation.state_vector import StateVectorSimulator\n",
    "from QuICT.algorithm.quantum_machine_learning.ansatz_library import *\n",
    "from QuICT.core.circuit import Circuit\n",
    "from QuICT.core.gate import *\n",
    "from QuICT.algorithm.quantum_machine_learning.utils import Hamiltonian\n",
    "from QuICT.algorithm.quantum_machine_learning.differentiator import Differentiator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESIZE = (4, 4)\n",
    "QUBIT = int(np.log2(RESIZE[0] * RESIZE[1]) + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples:  60000\n",
      "Testing examples:  10000\n",
      "Filtered training examples:  12049\n",
      "Filtered testing examples:  1968\n",
      "Label:  tensor(False)\n",
      "Remaining training examples:  10338\n",
      "Remaining testing examples:  1793\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root=\"./data/\", train=True, download=True)\n",
    "test_data = datasets.MNIST(root=\"./data/\", train=False, download=True)\n",
    "train_X = train_data.data\n",
    "train_Y = train_data.targets\n",
    "test_X = test_data.data\n",
    "test_Y = test_data.targets\n",
    "print(\"Training examples: \", len(train_Y))\n",
    "print(\"Testing examples: \", len(test_Y))\n",
    "\n",
    "\n",
    "def filter_targets(X, Y, class0=3, class1=6):\n",
    "    idx = (Y == class0) | (Y == class1)\n",
    "    X, Y = (X[idx], Y[idx])\n",
    "    Y = Y == class1\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "train_X, train_Y = filter_targets(train_X, train_Y)\n",
    "test_X, test_Y = filter_targets(test_X, test_Y)\n",
    "print(\"Filtered training examples: \", len(train_Y))\n",
    "print(\"Filtered testing examples: \", len(test_Y))\n",
    "print(\"Label: \", train_Y[200])\n",
    "plt.imshow(train_X[200], cmap=\"gray\")\n",
    "\n",
    "\n",
    "def downscale(X, resize):\n",
    "    transform = transforms.Resize(size=resize)\n",
    "    X = transform(X) / 255.0\n",
    "    return X\n",
    "\n",
    "\n",
    "resized_train_X = downscale(train_X, RESIZE)\n",
    "resized_test_X = downscale(test_X, RESIZE)\n",
    "plt.imshow(resized_train_X[200], cmap=\"gray\")\n",
    "\n",
    "\n",
    "def remove_conflict(X, Y, resize):\n",
    "    x_dict = collections.defaultdict(set)\n",
    "    for x, y in zip(X, Y):\n",
    "        x_dict[tuple(x.numpy().flatten())].add(y.item())\n",
    "    X_rmcon = []\n",
    "    Y_rmcon = []\n",
    "    for x in x_dict.keys():\n",
    "        if len(x_dict[x]) == 1:\n",
    "            X_rmcon.append(np.array(x).reshape(resize))\n",
    "            Y_rmcon.append(list(x_dict[x])[0])\n",
    "    X = np.array(X_rmcon)\n",
    "    Y = np.array(Y_rmcon)\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "nocon_train_X, nocon_train_Y = remove_conflict(resized_train_X, train_Y, RESIZE)\n",
    "nocon_test_X, nocon_test_Y = remove_conflict(resized_test_X, test_Y, RESIZE)\n",
    "print(\"Remaining training examples: \", len(nocon_train_Y))\n",
    "print(\"Remaining testing examples: \", len(nocon_test_Y))\n",
    "\n",
    "\n",
    "def binary_img(X, threshold):\n",
    "    X = X > threshold\n",
    "    X = X.astype(np.int16)\n",
    "    return X\n",
    "\n",
    "\n",
    "threshold = 0.5\n",
    "bin_train_X = binary_img(nocon_train_X, threshold)\n",
    "bin_test_X = binary_img(nocon_test_X, threshold)\n",
    "\n",
    "\n",
    "def encoding_img(X, encoding):\n",
    "    data_circuits = []\n",
    "    for i in tqdm.tqdm(range(len(X))):\n",
    "        data_circuit = encoding(X[i])\n",
    "        data_circuits.append(data_circuit)\n",
    "\n",
    "    return data_circuits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1  # 一次迭代使用的样本数\n",
    "SEED = 17  # 随机数种子\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "ms.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = bin_train_X\n",
    "test_X = bin_test_X\n",
    "train_Y = nocon_train_Y\n",
    "test_Y = nocon_test_Y\n",
    "\n",
    "train_dataset = Dataset(train_X, train_Y)\n",
    "test_dataset = Dataset(test_X, test_Y)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10338/10338 [03:35<00:00, 48.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test grad\n",
    "quict_frqi = FRQI(2)\n",
    "hiq_frqi = HIQFRQI(RESIZE[0] * RESIZE[1])\n",
    "quict_sim = StateVectorSimulator(device=\"GPU\")\n",
    "hiq_sim = Simulator('mqvector', QUBIT)\n",
    "hiq_datacir = hiq_frqi()\n",
    "quict_qnn = CRADL(QUBIT, color_qubit=1, readout=0)\n",
    "hiq_qnn = HIQAnsatz(QUBIT, color_qubit=QUBIT - 2, readout=QUBIT - 1)\n",
    "hiq_encoder = hiq_frqi()\n",
    "hiq_encoder.as_encoder()\n",
    "hiq_ansatz = hiq_qnn()\n",
    "hiq_ansatz.as_ansatz()\n",
    "hiq_cir = hiq_encoder + hiq_ansatz\n",
    "differentiator = Differentiator(device=\"GPU\")\n",
    "quict_ham = Hamiltonian([[1.0, \"Z0\"]])\n",
    "hiq_ham = HiqHamiltonian(QubitOperator(\"Z\" + str(QUBIT - 1)))\n",
    "\n",
    "\n",
    "loader = tqdm.tqdm(train_loader, leave=True)\n",
    "for it, (x_train, y_train) in enumerate(loader):\n",
    "    params = np.ones((1, (QUBIT - 2) * 4))\n",
    "    hiq_sim.reset()\n",
    "    quict_datacir = quict_frqi(x_train[0], use_qic=False)\n",
    "    quict_modelcir = quict_qnn.init_circuit(params=params)\n",
    "    quict_params = quict_qnn.params\n",
    "    quict_cir = Circuit(QUBIT)\n",
    "    quict_datacir | quict_cir(list(range(1, QUBIT)))\n",
    "    sv = quict_sim.run(quict_cir)\n",
    "    \n",
    "    \n",
    "    quict_modelcir | quict_cir(list(range(QUBIT)))\n",
    "    quict_sv = quict_sim.run(quict_cir)\n",
    "    quict_vars, poss = differentiator.run(quict_modelcir, quict_params, quict_sv, quict_ham)\n",
    "    quict_grad = quict_vars.grads\n",
    "    \n",
    "    # hiq_sim.apply_circuit(hiq_cir, list(x_train[0].flatten()) + list(params[0] / 2))\n",
    "    grad_ops = hiq_sim.get_expectation_with_grad(hams=hiq_ham, circ_right=hiq_cir)\n",
    "    hiq_img = np.array(list(x_train[0].flatten())).reshape(1, RESIZE[0] * RESIZE[1])\n",
    "    hiq_params = np.array(list(params[0] / 2))\n",
    "    re = grad_ops(hiq_img, hiq_params)\n",
    "    hiq_grad = re[2]\n",
    "    \n",
    "    # hiq_sv = hiq_sim.get_qs()\n",
    "    if abs(np.linalg.norm(quict_grad*2 - hiq_grad)) > 1e-12:\n",
    "        print(it)\n",
    "        print(\"FALSE\")\n",
    "        print(x_train[0])\n",
    "        print(\"quict\", quict_grad)\n",
    "        print(\"hiq\", hiq_grad)\n",
    "        break\n",
    "print(\"PASS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
