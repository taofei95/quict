# 基于图学习及强化学习的量子电路映射算法

本节将介绍如何使用强化学习算法 DQN 求解量子电路映射问题。

## 术语定义

| 名称     | 含义                                                   |
| :------- | :----------------------------------------------------- |
| 拓扑     | 实际的量子电路中允许的双比特门连接性关系               |
| 逻辑电路 | 待映射的量子电路，其双比特门连接性可能并不满足拓扑约束 |
| 物理电路 | 实际可执行的量子电路，其双比特门关系必须满足拓扑约束   |

映射算法初始化时，逻辑电路就是算法输入的电路，物理电路为空。算法执行过程中，可满足的门越来越多，它们将从逻辑电路中删去，并添加到物理电路中。逻辑电路将随着算法运行变得越来越小，而物理电路越来越大。


## 图学习

电路中的多个量子门作用在同一个比特上时，必须按照它们在电路中的先后顺序执行。我们可以用一个有向无环图来表示这种先后顺序。由于在映射问题中，我们着重考虑双比特门，因此只将双比特门的依赖关系构建出有向无环图。图中的每个节点代表电路中的一个双比特门，图中的有向边 $u \rightarrow v$ 表示双比特门 $u$ 必须先于双比特门 $v$ 被执行。每个双比特门的标号，在电路中的位置等信息，被结合在一起处理为某种标记，与该双比特门对应的节点相关连。因此，这样的一个有向图唯一地描述了当前电路中的双比特门相互关系。

我们利用图学习技术来提取该有向图的信息，获得一个紧凑的向量表示。我们期望这个向量表示足够后续的神经网络理解有关图的信息。该图网络的结构大致如下：

1. Embedding 层：将输入的有向图上的离散数据转化为向量表示，可训练
2. 卷积层：若干层可训练的卷积层，交换图上的每个节点与其邻居的信息
3. 聚合层：将所有节点的信息聚合在一起，获得一个向量表示

## 强化学习

我们选取 DQN 来完成双比特门的选择。首先，记当前拓扑关系，所有允许插入 SWAP 门的位置集合为 $A$，这就是所有可行的选择。图学习阶段给出的向量表示，实际上表示了输入的状态信息，我们将它记为 $s$。在状态 $s$ 下选取了某个位置的插入 SWAP 门，记作执行了操作 $a$。如果该 SWAP 操作后使得电路中 $k$ 个原本不能满足拓扑约束的门可被执行，则获得 $k \cdot C$ 奖励，其中 $C$ 是某个常数。如果插入 SWAP 门后没有任何门可被执行，则不获得奖励。同时，我们给每个操作添加一个较小的惩罚项，来避免算法在无法获得奖励的状态中反复循环。对于 $N$ 比特的拓扑结构，在最坏的情况下，总可以通过插入 $N$ 个 SWAP 门，使得任意两个比特相邻。平均而言我们认为，使用最原始的贪心算法， $\frac{N}{2}$ 次操作足够获得一次奖励，因此我们设置每次操作的惩罚项为 $\frac{2 \cdot C}{N}$，其中 $C$ 就是因门被执行而获得的奖励中的常数，$N$ 是比特数。因此，总的奖励项为

$$
R(s, a) = C \cdot \#\{executed\} - \frac{2 \cdot C}{N}
$$

我们的算法目标是，最大化奖励

$$
V(s_0) = \max_{\{a_t\}} \sum_{t} \gamma^t \cdot R(s_t, a_t)
$$

假设状态 $s$ 下，执行操作 $a$ 后状态变为 $s^\prime$，根据 Bellman 方程，

$$
V^*(s) = \max_{a} \left\{ R(s, a) + \gamma \cdot V^*(s^\prime)  \right\}
$$

由于量子电路映射问题中，每个操作的转移都是确定性的，因此上述等式中并没有出现依据概率的求和项。

简单地利用若干全连接层，将图学习给出的向量表示调整为 $|A|$ 长度的向量，其中 $A$ 是所有可能的 SWAP 插入位置。该向量的每个位置，给出了当前状态下执行每个操作后的预期 Q 值。利用 Bellman 方程优化该网络，即获得了一个具有求解量子电路映射问题能力的智能体。

## 算法描述

利用神经网络，提取一个有向无环图的特征，用一个固定长度的向量来表示它。接下来利用 DQN 来选择合适的位置插入 SWAP 门。在这样的表示方法下，量子电路映射的过程可以概括如下：

1. 初始化物理电路为空，逻辑电路为待映射的电路，构造逻辑电路的有向无环图表示
2. 如果此时逻辑电路中存在部分无需任何操作就可以直接放入物理电路，那么直接将这部分双比特门转移至物理电路
3. 在有向无环图表示中删去上一步中删除的双比特门的节点（如果存在），更新节点标号
4. 此时如果逻辑电路已经被删空，则算法结束
5. 将有向无环图表示送入图神经网络，得到图的表示向量
6. 将图表示送入 DQN，它根据拓扑约束给出一个合法的物理电路中的双比特门位置
7. 在物理电路中选择该位置插入 SWAP 门
8. 因为 SWAP 的插入，有向无环图的标号需要更新
9. 跳转至 2 步骤，重复执行

## 示例代码

### AI 推理

由于 DQN 需要基于拓扑执行决策，每个拓扑对应的网络略有不同，因此针对不同拓扑执行推理时，需要加载不同的模型文件。我们对几种常见拓扑提供了预训练的模型，可以直接用于映射算法。在映射算法初始化时，传入拓扑描述，以及模型路径文件夹（默认为 `./model`），算法会加载路径文件夹下与拓扑同名的模型描述文件。此时直接调用 `execute` 方法即可执行映射算法。

```python
from os import path as osp

from QuICT.core import Circuit, Layout
from QuICT.core.gate import *

from QuICT.qcda.mapping.ai.rl_mapping import RlMapping


def test_main():
    layout_path = osp.join(osp.dirname(__file__), "../layout")
    layout_path = osp.join(layout_path, "grid_3x3.json")
    layout = Layout.load_file(layout_path)
    # It will load model with the same name from model path.
    # If there's no model, you can try train first.
    mapper = RlMapping(layout=layout)
    circ = Circuit(9)
    circ.random_append(random_params=True)
    circ.draw(filename="before_mapping")
    mapped_circ = mapper.execute(circ)
    mapped_circ.draw(filename="mapped_circ")


if __name__ == "__main__":
    test_main()
```

### AI 训练

执行 `./QuICT/qcda/mapping/ai/train/train_rl.py` 脚本即可。`Trainer` 类需要一个 `TrainConfig` 实例进行实例化。只需向 `TrainConfig` 写入拓扑结构等关键信息，`Trainer` 就能自动开启 DQN 的训练过程并记录下最优模型。
